---
title: Oculus Lipsync Unity Integration Guide
---

The Oculus Lipsync Unity integration is a tool used to sync avatar lip movements to speech sounds. Oculus Lipsync analyzes an audio input stream from a microphone input or an audio file, and either offline or in real-time predicts a set of values (called [visemes](/documentation/audiosdk/latest/concepts/audio-ovrlipsync-viseme-reference/)) which may be used to animate the lips of an avatar.

<p alt="" class="img" src="/images/documentationaudiosdklatestconceptsbook-audio-ovrlipsync-0.gif" style="width:100%;max-width:300pt" title="Geometry morph target using Oculus lipsync to say: Welcome to the Oculus Lipsync demo">![](/images/documentationaudiosdklatestconceptsbook-audio-ovrlipsync-0.gif "Geometry morph target using Oculus lipsync to say: Welcome to the Oculus Lipsync demo")

This guide describes how to install and use Oculus Lipsync for Unity.

* **[Overview](/documentation/audiosdk/latest/concepts/audio-ovrlipsync-overview/)**
* **[Requirements](/documentation/audiosdk/latest/concepts/audio-ovrlipsync-req/)**  

* **[Download and Setup](/documentation/audiosdk/latest/concepts/audio-ovrlipsync-setup/)**  

* **[Using the Lipsync Integration](/documentation/audiosdk/latest/concepts/audio-ovrlipsync-sample-details/)**  

* **[Precomputing Visemes to Save CPU](/documentation/audiosdk/latest/concepts/audio-ovrlipsync-precomputed/)**  

* **[Exploring Oculus Lipsync with the Sample Scene](/documentation/audiosdk/latest/concepts/audio-ovrlipsync-sample/)**
* **[Viseme Reference Images](/documentation/audiosdk/latest/concepts/audio-ovrlipsync-viseme-reference/)**

